{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79f8c357",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    " \n",
    "def load_dataset(file_path): \n",
    "    return pd.read_csv(file_path) \n",
    "\n",
    "def numerical_stats(df, column): \n",
    "    data = df[column].dropna() \n",
    "    mean = np.mean(data) \n",
    "    median = np.median(data) \n",
    "    mode = data.mode()[0] if not data.mode().empty else None \n",
    "    std_dev = np.std(data, ddof=1) \n",
    "    variance = np.var(data, ddof=1) \n",
    "    data_range = np.max(data) - np.min(data) \n",
    "    \n",
    "    print(f\"Statistics for {column}:\") \n",
    "    print(f\"Mean: {mean}\") \n",
    "    print(f\"Median: {median}\") \n",
    "    print(f\"Mode: {mode}\") \n",
    "    print(f\"Standard Deviation: {std_dev}\") \n",
    "    print(f\"Variance: {variance}\") \n",
    "    print(f\"Range: {data_range}\\n\") \n",
    "    \n",
    "    return data \n",
    "\n",
    "def detect_outliers(data): \n",
    "    Q1 = np.percentile(data, 25) \n",
    "    Q3 = np.percentile(data, 75) \n",
    "    IQR = Q3 - Q1 \n",
    "    lower_bound = Q1 - 1.5 * IQR \n",
    "    upper_bound = Q3 + 1.5 * IQR \n",
    "    outliers = data[(data < lower_bound) | (data > upper_bound)] \n",
    "    \n",
    "    print(f\"Outliers: {outliers.tolist()}\\n\") \n",
    "\n",
    "def plot_numerical_distribution(data, column): \n",
    "    plt.figure(figsize=(12, 5)) \n",
    "     \n",
    "    plt.subplot(1, 2, 1) \n",
    "    sns.histplot(data, bins=20, kde=True) \n",
    "    plt.title(f'Histogram of {column}') \n",
    "     \n",
    "    plt.subplot(1, 2, 2) \n",
    "    sns.boxplot(x=data) \n",
    "    plt.title(f'Boxplot of {column}') \n",
    "     \n",
    "    plt.show() \n",
    "\n",
    "def categorical_frequency(df, column): \n",
    "    category_counts = df[column].value_counts() \n",
    "     \n",
    "    print(f\"Frequency of categories in {column}:\") \n",
    "    print(category_counts, \"\\n\") \n",
    "     \n",
    "    return category_counts \n",
    "\n",
    "def plot_categorical_distribution(category_counts, column): \n",
    "    plt.figure(figsize=(12, 5)) \n",
    "     \n",
    "    plt.subplot(1, 2, 1) \n",
    "    category_counts.plot(kind='bar', color='skyblue') \n",
    "    plt.title(f'Bar Chart of {column}') \n",
    "     \n",
    "    plt.subplot(1, 2, 2) \n",
    "    category_counts.plot(kind='pie', autopct='%1.1f%%') \n",
    "    plt.title(f'Pie Chart of {column}') \n",
    "     \n",
    "    plt.show() \n",
    "\n",
    "def main(): \n",
    "    file_path = input(\"Enter dataset file path: \") \n",
    "    df = load_dataset(file_path) \n",
    "     \n",
    "    print(\"Columns in dataset:\", df.columns.tolist()) \n",
    "     \n",
    "    num_col = input(\"Enter numerical column for analysis: \") \n",
    "    num_data = numerical_stats(df, num_col) \n",
    "    detect_outliers(num_data) \n",
    "    plot_numerical_distribution(num_data, num_col) \n",
    "    \n",
    "    cat_col = input(\"Enter categorical column for frequency analysis: \") \n",
    "    cat_counts = categorical_frequency(df, cat_col) \n",
    "    plot_categorical_distribution(cat_counts, cat_col) \n",
    "\n",
    "if _name_ == \"_main_\": \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4248b5f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'] \n",
    "\n",
    "\n",
    "df = pd.read_csv(\"iris.csv\", names=column_names, header=0)  \n",
    "\n",
    "\n",
    "print(\"Dataset Preview:\") \n",
    "print(df.head()) \n",
    "\n",
    "\n",
    "x_column = df.columns[0]  \n",
    "y_column = df.columns[1]  \n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6)) \n",
    "sns.scatterplot(x=df[x_column], y=df[y_column]) \n",
    "plt.title(f'Scatter Plot: {x_column} vs {y_column}') \n",
    "plt.xlabel(x_column) \n",
    "plt.ylabel(y_column) \n",
    "plt.show() \n",
    "\n",
    "\n",
    "correlation = np.corrcoef(df[x_column], df[y_column])[0, 1] \n",
    "print(f'Pearson Correlation Coefficient between {x_column} and {y_column}: {correlation:.2f}') \n",
    "\n",
    "\n",
    "df_numeric = df.select_dtypes(include=[np.number])  \n",
    "cov_matrix = df_numeric.cov() \n",
    "print(\"\\nCovariance Matrix:\") \n",
    "print(cov_matrix) \n",
    "\n",
    "\n",
    "corr_matrix = df_numeric.corr() \n",
    "print(\"\\nCorrelation Matrix:\") \n",
    "print(corr_matrix) \n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5) \n",
    "plt.title('Correlation Matrix Heatmap') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "974f4fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./myenv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in ./myenv/lib/python3.12/site-packages (2.2.6)\n",
      "Requirement already satisfied: matplotlib in ./myenv/lib/python3.12/site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in ./myenv/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./myenv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./myenv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./myenv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./myenv/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./myenv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./myenv/lib/python3.12/site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./myenv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./myenv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./myenv/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./myenv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06087354",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.decomposition import PCA \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "df = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "\n",
    "if 'Id' in df.columns: \n",
    "    df = df.drop(columns=['Id'])  \n",
    "\n",
    "\n",
    "X = df.drop(columns=['variety'])  \n",
    "\n",
    "\n",
    "scaler = StandardScaler() \n",
    "X_scaled = scaler.fit_transform(X) \n",
    "\n",
    "\n",
    "pca = PCA(n_components=2) \n",
    "X_pca = pca.fit_transform(X_scaled) \n",
    "\n",
    "pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2']) \n",
    "pca_df['variety'] = df['variety'] \n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6)) \n",
    "sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='variety', palette='viridis', s=100, edgecolor='k') \n",
    "plt.title(\"PCA Visualization of Iris Dataset\") \n",
    "plt.xlabel(\"Principal Component 1\") \n",
    "plt.ylabel(\"Principal Component 2\") \n",
    "plt.legend() \n",
    "plt.show() \n",
    "\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7133662",
   "metadata": {},
   "outputs": [],
   "source": [
    "mport numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import accuracy_score, f1_score \n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('iris.csv') \n",
    "\n",
    "# Features and target\n",
    "X = df.iloc[:, :-1].values \n",
    "y = df.iloc[:, -1].values \n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ") \n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler() \n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "# k-NN evaluation function\n",
    "def evaluate_knn(k_values, weighted=False): \n",
    "    results = [] \n",
    "    for k in k_values: \n",
    "        model = KNeighborsClassifier(n_neighbors=k, weights='distance' if weighted else 'uniform')  \n",
    "        model.fit(X_train, y_train)  \n",
    "        y_pred = model.predict(X_test) \n",
    "        acc = accuracy_score(y_test, y_pred) \n",
    "        f1 = f1_score(y_test, y_pred, average='weighted') \n",
    "        results.append((k, acc, f1)) \n",
    "    return pd.DataFrame(results, columns=['k', 'Accuracy', 'F1-score']) \n",
    "\n",
    "# Evaluate\n",
    "k_values = [1, 3, 5] \n",
    "regular_knn_results = evaluate_knn(k_values, weighted=False) \n",
    "weighted_knn_results = evaluate_knn(k_values, weighted=True) \n",
    "\n",
    "# Print results\n",
    "print(\"Regular k-NN Results:\") \n",
    "print(regular_knn_results) \n",
    "print(\"\\nWeighted k-NN Results:\") \n",
    "print(weighted_knn_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
